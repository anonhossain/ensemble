# ğŸ§  Health Behavior Prediction Using Ensemble Learning

## ğŸ“Œ Project Overview  
This project demonstrates a hands-on approach to building a predictive model aimed at classifying health-related behaviorsâ€”specifically smoking and drinking statusâ€”based on physiological and lifestyle features. It follows a complete machine learning pipeline including preprocessing, feature engineering, model building, evaluation, and deployment.

---

## ğŸ” Key Highlights

### ğŸ“Š Data Preprocessing
- Cleaned dataset and handled missing values
- Encoded categorical variables into numerical format
- Normalized and scaled data for better model performance

### ğŸ§¬ Feature Engineering
- Engineered new features like **BMI** from height and weight
- Ranked features based on importance using tree-based models
![Feature Ranking](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/feature_ranking.PNG)

### ğŸ“¤ Data Splitting
- Used an 80-20 train-test split to evaluate model generalization

### ğŸ§  Machine Learning Techniques
- Implemented **Bagging**, **Voting**, **Boosting**, and **Stacking** classifiers
- Evaluated models using **Accuracy**, and **Confusion Matrix**
![Voting](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/voting%20result.PNG)
![Boosting](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/boosting_result.PNG)
![CatBoost](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/catBoosting.PNG)
![Stacking](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/stacking.PNG)

### ğŸ“ˆ Hyperparameter Tuning
- Applied **GridSearchCV** to find the best parameter combinations
- Tuned **XGBoost** and **LightGBM** for optimal performance
![Boosting Parameters](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/boosting%20parameters.PNG)

### ğŸ” Cross-Validation
- Used **K-Fold Cross-Validation** on XGBoost for stability and robustness
- Exported the final model as a `.joblib` file for deployment

![K fold](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/fold%205%20out%20of%201.PNG)
![Saved](https://github.com/anonhossain/ensemble/blob/main/result/screenshot/saved.PNG)

---

## ğŸ§° Technologies Used
- **Python**: Pandas, NumPy, Scikit-learn, XGBoost, LightGBM  
- **Visualization**: Matplotlib, Seaborn  
- **Model Serialization**: Joblib  

---

## ğŸ¯ Outcome
Trained and evaluated multiple ensemble models. The best-performing modelâ€”optimized using hyperparameter tuning and validated with K-Fold CVâ€”was saved for future deployment and prediction tasks.
